# Lições Aprendidas

### 1. O que deu certo?

- Ajuda e cooperatividade;
- Escolha de mais tarefas simples ao invés de poucas tarefas complexas;
- O compromisso da equipe para com a atividade;
- A troca de informações e a comunicação;
- As tarefas foram bem divididas e previamente documentadas no Notion;
- A divisão das tarefas se mostrou mais eficiente que fazer chamadas simultaneamente;
- A ideia de criar um template para as ISSUES e forçar a equipe a fazê-lo seguindo o mesmo padrão;
- Mais uma vez se mostrou eficaz a ideia de dividir o trabalho;

### 2. O que não deu muito certo?

- Não houve nada nessa etapa do projeto que não tenha dado certo;

### 3. O que podemos fazer na próxima atividade para tentar resolver o que não deu certo?

- Como todas as entregas foram realizadas com sucesso, não há nenhum ponto de atenção ou débito por parte dos membros da equipe. Todos estão de parabéns.

### 4. O que está deixando vocês em estado de alerta?

- Nenhum ponto de atenção/estado de alerta. Todas as atividades foram devidamente concluídas.

### 5. Aprendizados da atividade

- Pontuem os desafios mais relevantes encontrados na realização da atividade.
    - A implementação do código, especialmente a manutenção das expressões regulares foi um pouco trabalhosa de validar. Algumas sugestões da comunidade que não foram nem avaliadas, recusadas ou aceitas estavam desatualizadas, então não foram de tão grande ajuda em alguns cenários para resolver os problemas, fazendo com que nossas próprias soluções fossem adotadas.
- Quais as estratégias utilizadas para contornar estas dificuldades?
    - Tivemos que recorrer ao StackOverflow e ao Regex101 para testar regex de validação existentes e ir adaptando conforme o problema. Um ponto extremamente crítico é que não há nenhuma documentação para descrever melhor as Regex. Algumas Regexes são gigantes e um pouco “indecifráveis”.
- Como a equipe conseguiu superar as dificuldades envolvidas na implementação das CRs?
    - Com cooperação e ajuda entre si, através de pedidos de suporte via grupo no Whatsapp e também na última reunião feita no Google Meeting para fechar o projeto.
- Qual o grau de confiança que a análise de impacto apresentou para vocês?
    - Muito alto grau de confiança. Tínhamos segurança do que nos esperava em cada uma das CRs após analisar, avaliar e reavaliar cada um dos itens que elencamos de melhoria e correção de bugs.
- A margem de erro que vocês estimaram na atividade anterior era real? Justifique.
    - Sim, foi perfeitamente real e também percebemos que a nossa estimativa estava dentro dos parâmetros que definimos. A estimativa de tempo para algumas tarefas foi acima do necessário na prática, mas no geral todos os itens foram implementados, alguns com sobra de tempo. Devido a estimativa elevar e “puxar para cima” o tempo necessário, devido a especulação de complexidade e esforço, alguns cenários se provaram mais simples e poderiam ter tido uma estimativa menor (algo entre 1 ou 2 horas de GAP).
- Vocês acreditam que realizar a análise de impacto e estimativa de atividades contribuiu positivamente na execução da CR? Faria alguma diferença absorver a implementação da mudança sem ela?
    - Contribuiu significativamente. Sem a análise de impacto poderíamos ter feito as CRs na ordem incorreta, sem visão de esforço e priorização quanto a complexidade/esforço e termos dedicado mais tempo a resolver as CRs com expressões regulares muito complexas primeiro, ao invés de focar logo nas mais simples. Além disso a análise de impacto ajudou muito a ter uma noção dos locais que deveriam ter sido alterados dentro do código. Foi uma espécie de “reconhecime